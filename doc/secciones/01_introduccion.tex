\chapter{Introduction}
\section{Motivation}
Machine learning has had a huge impact recently across many sectors such as the automobile, medical or defense industries. This progress comes along with more complex machine learning models where many parameters need to be adjusted to optimize the usefulness of the resulting trained model. Optimizing these parameters is not easy work and it is usually a time-consuming task as well as requires expertise to do it properly.

The traditional way of performing parameter optimization is Grid Search which is an exhaustive search through a manually specified subset of the parameters space of a learning algorithm ~\cite{wikipedia-Hyperparameter_optimization}. The model has to be trained with all the possible combinations for the values of the different parameters; this can take a lot of time for models where we want to test several parameters with many possible values each one. For example, the time complexity of Grid Search for a model with two parameters where $n$ values are tested for the first parameter and $m$ for the second one is $O(n \times m)$.

Another well-known approach is called Evolutionary Optimization which uses Evolutionary Algorithms for parameter optimization. Evolutionary algorithms (to be further known as an EA) are optimization algorithms that use mechanisms inspired by biological processes such as reproduction, mutation or selection. They apply these mechanisms over a population which consists of a set of candidate solutions (in this case a set of values for the parameters of the model we want to train) known as individuals. Each individual is evaluated with a fitness function that determines the quality of a solution ~\cite{wikipedia-Evolutionary_Algorithm}; for a machine learning model this fitness model can be the accuracy of its predictions.

Evolutionary algorithms are a successful approach to solve many difficult problems because they are easy to understand, simple to code and have a good performance ~\cite{Intro-to-EA}. But it can take a considerable amount of time to run an EA on a single machine depending on the complexity of the fitness function, the size of the population and how many generations we want to simulate.

Today we have an incredible amount of resources available for computation, most of them are wasted being partially idle all the time. What about using these potential resources to help science by running evolutionary algorithms in a distributed way?

This project aims to take advantage of this opportunity by providing a common platform to deploy distributed evolutionary algorithms and enabling both tech-savvy and non-tech-savvy people to contribute to solving problems with their machines.

We cannot control how the users of the platform will behave in terms of how much time will they invest collaborating in our platform, therefore, we need our system to scale well with an ephemeral and heterogeneous environment where nodes can disappear without previous notice and can have an important performance difference between each other, or even being implemented in different languages. 


\section{Objectives}
The overall objective of this project is to provide a common platform where researchers and contributors run Evolutionary Algorithms in a distributed way while minimizing the effort they need to make in order to do so. We can break it down in the following objectives:

\begin{itemize}
    \item Minimize the effort a user needs to make in order to upload a new problem to the platform or start collaborating with an already existing problem. 
    
    \item Minimize the number of single points of failure within the system while providing a scalable and partition-resilient design where nodes are heterogeneous and ephemeral.
    
    \item Evaluate the performance of the platform against a non-distributed implementation.
\end{itemize}
